{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44a24cbb-2112-43f7-9569-0bdb8a231e62",
   "metadata": {},
   "source": [
    "Multi-user RAG pipeline with archive support using FAISS + OpenAI embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f8212-4122-48b7-bf12-b33497c01d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai faiss-cpu numpy json5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f58b419c-462c-4022-b37c-343d853dd1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "EMBED_MODEL = \"text-embedding-ada-002\"\n",
    "EMBED_DIM = 1536\n",
    "\n",
    "# Global dictionary to store user-specific FAISS indices\n",
    "user_indexes = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee782098-32b8-474d-8956-cbff39b4cd52",
   "metadata": {},
   "source": [
    "FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3d9caa-6afa-470e-9aa9-d69fa5f879ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_index(user_id: str):\n",
    "    \"\"\"\n",
    "    Returns (or creates) a FAISS index & stored_facts list for the given user_id.\n",
    "    \"\"\"\n",
    "    if user_id not in user_indexes:\n",
    "        user_indexes[user_id] = {\n",
    "            \"index\": faiss.IndexFlatL2(EMBED_DIM),\n",
    "            \"stored_facts\": []  # List of tuples: (fact_text, fact_id)\n",
    "        }\n",
    "    return user_indexes[user_id]\n",
    "\n",
    "def embed_text(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calls OpenAI to embed text and returns a numpy array.\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        model=EMBED_MODEL,\n",
    "        input=[text]  \n",
    "    )\n",
    "    emb = response.data[0].embedding\n",
    "    return np.array(emb, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f9a858-0ff7-41a5-89dd-59c692848d16",
   "metadata": {},
   "source": [
    "Process Memory Updates with time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f1b1bc5-ffd8-4dab-bb99-4ff869fe1c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def process_memory_updates(user_id: str, updated_mem: dict):\n",
    "    \"\"\"\n",
    "    Processes memory updates and assigns timestamps to new facts.\n",
    "    \"\"\"\n",
    "    if \"memories\" not in updated_mem:\n",
    "        return\n",
    "\n",
    "    current_time = time.time()  # Timestamp for new session\n",
    "\n",
    "    for mem_item in updated_mem[\"memories\"]:\n",
    "        evt = mem_item.get(\"event\", \"\")\n",
    "        cat = mem_item.get(\"category\", \"\")\n",
    "        content = mem_item.get(\"content\", \"\")\n",
    "        fact_id = mem_item.get(\"id\", \"\")\n",
    "        fact_text = f\"{cat}: {content}\"\n",
    "\n",
    "        if evt in (\"ADD\", \"UPDATE\"):\n",
    "            add_fact(user_id, fact_text, fact_id, current_time) \n",
    "\n",
    "def add_fact(user_id: str, fact_text: str, fact_id: str, timestamp: float):\n",
    "    \"\"\"\n",
    "    Adds a timestamp when storing facts in FAISS for tracking recent sessions.\n",
    "    \"\"\"\n",
    "    user_data = get_user_index(user_id)\n",
    "    vec = embed_text(fact_text).reshape(1, -1)\n",
    "    user_data[\"index\"].add(vec)\n",
    "    user_data[\"stored_facts\"].append((fact_text, fact_id, timestamp))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d2ae1-20ec-4514-9a5c-55ff3bd543aa",
   "metadata": {},
   "source": [
    "Retrieve Long-Term Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3655a40d-661a-43b8-8137-ae999ba49a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_long_term_facts(user_id: str):\n",
    "    \"\"\"\n",
    "    Retrieves ALL stored facts, ensures no duplicates, and prioritizes the most recent session.\n",
    "    \"\"\"\n",
    "    user_data = get_user_index(user_id)\n",
    "    if user_data[\"index\"].ntotal == 0:\n",
    "        return {}\n",
    "\n",
    "    # Retrieve ALL stored facts sorted by newest first\n",
    "    indexed_facts = sorted(user_data[\"stored_facts\"], key=lambda x: x[2], reverse=True)  \n",
    "\n",
    "    categorized_facts = {\"Recent Session\": [], \"Long-Term\": []}\n",
    "    seen_facts = set()  # unique\n",
    "\n",
    "    # Assign most recent session to 'local_evidence'\n",
    "    if indexed_facts:\n",
    "        recent_fact = indexed_facts[0][0]\n",
    "        if recent_fact not in seen_facts:\n",
    "            categorized_facts[\"Recent Session\"].append(recent_fact)\n",
    "            seen_facts.add(recent_fact)\n",
    "\n",
    "    # Assign all other to 'long_term_evidence' \n",
    "    for fact_text, fact_id, timestamp in indexed_facts[1:]:  \n",
    "        if fact_text not in seen_facts:\n",
    "            categorized_facts[\"Long-Term\"].append(fact_text)\n",
    "            seen_facts.add(fact_text)\n",
    "\n",
    "    return categorized_facts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d3d446-12a4-4ac6-b8f5-b05de76bcaac",
   "metadata": {},
   "source": [
    "Generate GPT Response Based on Multi-Session Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d555b7-1fa6-43ba-808c-c31b2b8ee0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=\"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\")  # Replace with your actual key\n",
    "\n",
    "def generate_long_term_json_response(user_id: str, user_query: str):\n",
    "    \"\"\"\n",
    "    Generates a structured long-term memory response using OpenAI API.\n",
    "    \"\"\"\n",
    "    retrieved_facts = retrieve_long_term_facts(user_id)  # Retrieves ALL stored facts\n",
    "\n",
    "    local_evidence = retrieved_facts.get(\"Recent Session\", [])\n",
    "    long_term_evidence = retrieved_facts.get(\"Long-Term\", [])\n",
    "\n",
    "    json_template = {\n",
    "        \"question\": user_query,\n",
    "        \"local_evidence\": local_evidence,\n",
    "        \"long_term_evidence\": long_term_evidence,\n",
    "        \"final_answer\": \"...\"\n",
    "    }\n",
    "\n",
    "    rag_prompt = f\"\"\"\n",
    "    You are an AI counselor summarizing user experiences across multiple conversations.\n",
    "    \n",
    "    ## Local Evidence (most recent session, prioritize this)\n",
    "    {json.dumps(local_evidence, indent=4)}\n",
    "\n",
    "    ## Long-Term Evidence (all past sessions, do not ignore)\n",
    "    {json.dumps(long_term_evidence, indent=4)}\n",
    "\n",
    "    **INSTRUCTIONS:**\n",
    "    1️⃣ **You MUST consider all evidence from past sessions, but prioritize recent session first.**  \n",
    "    2️⃣ **Do NOT say 'evidence unavailable' if past conversations exist.**  \n",
    "    3️⃣ **Answer in a structured and concise manner.**  \n",
    "\n",
    "    Now, use the retrieved facts to answer: \"{user_query}\".\n",
    "\n",
    "    **STRICT OUTPUT FORMAT:**\n",
    "    ```json\n",
    "    {json.dumps(json_template, indent=4)}\n",
    "    ```\n",
    "    **Do NOT include explanations, preambles, or extra text.**\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"system\", \"content\": rag_prompt}],\n",
    "            response_format={\"type\": \"json_object\"},  \n",
    "            max_tokens=1024,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        # Extract JSON content from GPT response\n",
    "        structured_output = response.choices[0].message.content  \n",
    "\n",
    "        # Convert from string to JSON object\n",
    "        return json.loads(structured_output)\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"❌ ERROR: GPT failed to return valid JSON!\")\n",
    "        return None  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56cb3af-d084-46ca-967f-ec827502ec4c",
   "metadata": {},
   "source": [
    "Demo Test for Long-Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6e63545-2ee5-4396-88f3-c37dc7188c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Session 1 Processed]\n",
      "[Session 2 Processed]\n",
      "[Session 3 Processed]\n",
      "[Session 4 Processed]\n",
      "[FINAL LONG-TERM MEMORY RESPONSE]:\n",
      "\n",
      "{\n",
      "    \"question\": \"How did Maya's feelings of inadequacy manifest before she sought support, and what specific comparison prompted her to feel this way?\",\n",
      "    \"local_evidence\": [\n",
      "        \"Behavioral Patterns: She started writing down her achievements to feel more grounded\"\n",
      "    ],\n",
      "    \"long_term_evidence\": [\n",
      "        \"Relationships: Compares herself to her cousin who is excelling in medicine\",\n",
      "        \"Relationships: Parents expect her to go to medical school, but she is unsure\",\n",
      "        \"Demographics: Maya, 2nd-year Biochemistry student\",\n",
      "        \"Mental State: Feels anxious about grades and self-worth\"\n",
      "    ],\n",
      "    \"final_answer\": \"Maya's feelings of inadequacy manifested in her anxiety about grades and self-worth, leading her to start writing down her achievements to feel more grounded. The specific comparison that prompted her feelings of inadequacy was her cousin excelling in medicine, coupled with her parents' expectations for her to pursue medical school, despite her uncertainty.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def simulate_real_conversations():\n",
    "    user_id = \"user_7\"\n",
    "\n",
    "    # First session (conversation)\n",
    "    session_1 = {\"memories\": [\n",
    "        {\"id\": \"uuid-1\", \"content\": \"Maya, 2nd-year Biochemistry student\", \"category\": \"Demographics\", \"event\": \"ADD\"},\n",
    "        {\"id\": \"uuid-2\", \"content\": \"Feels anxious about grades and self-worth\", \"category\": \"Mental State\", \"event\": \"ADD\"}\n",
    "    ]}\n",
    "    process_memory_updates(user_id, session_1)\n",
    "    print(\"[Session 1 Processed]\")\n",
    "\n",
    "    # Second \n",
    "    session_2 = {\"memories\": [\n",
    "        {\"id\": \"uuid-3\", \"content\": \"Parents expect her to go to medical school, but she is unsure\", \"category\": \"Relationships\", \"event\": \"ADD\"}\n",
    "    ]}\n",
    "    process_memory_updates(user_id, session_2)\n",
    "    print(\"[Session 2 Processed]\")\n",
    "\n",
    "    # Third \n",
    "    session_3 = {\"memories\": [\n",
    "        {\"id\": \"uuid-4\", \"content\": \"Compares herself to her cousin who is excelling in medicine\", \"category\": \"Relationships\", \"event\": \"ADD\"}\n",
    "    ]}\n",
    "    process_memory_updates(user_id, session_3)\n",
    "    print(\"[Session 3 Processed]\")\n",
    "\n",
    "    # latest\n",
    "    session_4 = {\"memories\": [\n",
    "        {\"id\": \"uuid-5\", \"content\": \"She started writing down her achievements to feel more grounded\", \"category\": \"Behavioral Patterns\", \"event\": \"ADD\"}\n",
    "    ]}\n",
    "    process_memory_updates(user_id, session_4)\n",
    "    print(\"[Session 4 Processed]\")\n",
    "\n",
    "    # Ask a long-term memory question\n",
    "    long_term_question = \"How did Maya's feelings of inadequacy manifest before she sought support, and what specific comparison prompted her to feel this way?\"\n",
    "\n",
    "    # Retrieve JSON output\n",
    "    final_output = generate_long_term_json_response(user_id, long_term_question)\n",
    "\n",
    "\n",
    "    print(\"[FINAL LONG-TERM MEMORY RESPONSE]:\\n\")\n",
    "    print(json.dumps(final_output, indent=4))\n",
    "\n",
    "simulate_real_conversations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fceec7f-de04-4b59-aee6-8072b8573446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a434a4-2689-4daf-90dc-0ecb0dd4116e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724be496-70d7-468b-be1c-faf11eab8d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98dac8b5-d693-48ee-9435-6cc69711e3f4",
   "metadata": {},
   "source": [
    "Memory Extraction (ensure json format/without updating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a6026f1-7605-4bbe-92d2-f93997d0acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_memories_from_conversation(conversation: str, session_name: str, user_id: str):\n",
    "    \"\"\"\n",
    "    Extracts structured memory facts from a conversation session and immediately stores them in FAISS.\n",
    "    \"\"\"\n",
    "    extraction_prompt = f\"\"\"\n",
    "    You are an AI assistant that extracts structured memory facts from conversations.\n",
    "    \n",
    "    ## Conversation Transcript:\n",
    "    {conversation}\n",
    "\n",
    "    ## Task:\n",
    "    Extract facts about the student using these categories:\n",
    "    \n",
    "    1️⃣ **Demographics**: Name, age, major, university year, cultural background  \n",
    "    2️⃣ **Relationships**: Family dynamics, romantic status, peer conflicts, social support  \n",
    "    3️⃣ **Mental State**: Persistent emotions (anxiety, loneliness), self-perception, stress triggers  \n",
    "    4️⃣ **Academic Context**: Course workload, GPA pressure, career aspirations  \n",
    "    5️⃣ **Behavioral Patterns**: Sleep habits, coping mechanisms, health routines  \n",
    "    6️⃣ **Life Events**: Transitions, trauma, upcoming challenges  \n",
    "    7️⃣ **Resources**: Support systems, positive hobbies, personal strengths  \n",
    "\n",
    "    ## STRICT OUTPUT FORMAT:\n",
    "    ```json\n",
    "    {{\n",
    "        \"session\": \"{session_name}\",\n",
    "        \"memories\": [\n",
    "            {{\"id\": \"uuid-1\", \"content\": \"...\", \"category\": \"Demographics\", \"event\": \"ADD\"}},\n",
    "            {{\"id\": \"uuid-2\", \"content\": \"...\", \"category\": \"Mental State\", \"event\": \"ADD\"}}\n",
    "        ]\n",
    "    }}\n",
    "    ```\n",
    "\n",
    "    **DO NOT INCLUDE explanations, preambles, or extra text.**\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"system\", \"content\": extraction_prompt}],\n",
    "            response_format={\"type\": \"json_object\"},  \n",
    "            max_tokens=512,\n",
    "            temperature=0.5\n",
    "        )\n",
    "\n",
    "        extracted_memory = response.choices[0].message.content\n",
    "        extracted_memory_json = json.loads(extracted_memory)  # Convert JSON string to Python dict\n",
    "\n",
    "        # Send extracted memory directly to FAISS\n",
    "        process_memory_updates(user_id, extracted_memory_json)\n",
    "\n",
    "        print(f\"[Memory Stored] Extracted {len(extracted_memory_json['memories'])} facts for {user_id}\")\n",
    "\n",
    "        return extracted_memory_json  \n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"❌ ERROR: GPT failed to return valid JSON for {session_name}!\")\n",
    "        return None  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3301358d-5481-4383-8fbb-e6b9c8925819",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2d59902-f99d-4458-bd05-3973cb715c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory Stored] Extracted 5 facts for user_alex\n"
     ]
    }
   ],
   "source": [
    "test_conversation = \"\"\"\n",
    "Student: Hi, I'm Alex, a 3rd-year Computer Science student. I’ve been feeling really anxious about my workload.\n",
    "Counselor: That sounds tough, Alex. What’s making it feel overwhelming?\n",
    "Student: I have two major projects due next week, and I’m struggling to stay focused.\n",
    "Counselor: That’s a lot to handle. Have you found any strategies that help?\n",
    "Student: Not really. I tend to procrastinate, which makes it worse.\n",
    "Counselor: That makes sense. Have external pressures contributed to this stress?\n",
    "Student: Yeah, my parents expect me to maintain a high GPA, and I don’t want to let them down.\n",
    "\"\"\"\n",
    "\n",
    "# Extract & store memory for Alex\n",
    "user_id = \"user_alex\"\n",
    "extracted_memories = extract_memories_from_conversation(test_conversation, \"Session_Alex_1\", user_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38400ebe-631f-423b-8e78-ae4ced94bd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Retrieved Memory for Alex]:\n",
      "\n",
      "{\n",
      "    \"Recent Session\": [\n",
      "        \"Demographics: Name: Alex, Major: Computer Science, University Year: 3rd year\"\n",
      "    ],\n",
      "    \"Long-Term\": [\n",
      "        \"Mental State: Feeling anxious about workload\",\n",
      "        \"Behavioral Patterns: Struggling to stay focused and tends to procrastinate\",\n",
      "        \"Academic Context: Two major projects due next week\",\n",
      "        \"Relationships: Parents expect a high GPA\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve stored facts for Alex\n",
    "retrieved_facts = retrieve_long_term_facts(user_id)\n",
    "\n",
    "print(\"[Retrieved Memory for Alex]:\\n\")\n",
    "print(json.dumps(retrieved_facts, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81b8c4a0-3185-4f2b-8463-799dbafd760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINAL LONG-TERM MEMORY RESPONSE]:\n",
      "\n",
      "{\n",
      "    \"question\": \"How has Alex\\u0019s academic stress evolved over time, and what factors contributed to it?\",\n",
      "    \"local_evidence\": [\n",
      "        \"Demographics: Name: Alex, Major: Computer Science, University Year: 3rd year\"\n",
      "    ],\n",
      "    \"long_term_evidence\": [\n",
      "        \"Mental State: Feeling anxious about workload\",\n",
      "        \"Behavioral Patterns: Struggling to stay focused and tends to procrastinate\",\n",
      "        \"Academic Context: Two major projects due next week\",\n",
      "        \"Relationships: Parents expect a high GPA\"\n",
      "    ],\n",
      "    \"final_answer\": \"Alex's academic stress has been influenced by a combination of workload anxiety, difficulty in maintaining focus, and a tendency to procrastinate. The stress is exacerbated by the immediate pressure of two major projects due next week and the high GPA expectations from parents.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "long_term_question = \"How has Alex’s academic stress evolved over time, and what factors contributed to it?\"\n",
    "\n",
    "final_output = generate_long_term_json_response(user_id, long_term_question)\n",
    "\n",
    "print(\"[FINAL LONG-TERM MEMORY RESPONSE]:\\n\")\n",
    "print(json.dumps(final_output, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a017be0-f267-4441-b24b-2cb9483e21fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
